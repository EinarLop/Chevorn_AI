{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94eac6da-09a4-4b53-bad1-ae8a667112b6",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "477800ac-299b-4dca-984c-49bc9870bd6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T18:51:52.652834Z",
     "end_time": "2023-05-02T18:51:52.661551Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "worker_order_df = pd.read_csv('cleanworkorder.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T18:51:52.663195Z",
     "end_time": "2023-05-02T18:51:52.943277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e778683b-4ee9-491e-b6de-f87be353420b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T18:51:52.958934Z",
     "end_time": "2023-05-02T18:51:53.048719Z"
    }
   },
   "outputs": [],
   "source": [
    "job_df_predict = worker_order_df\n",
    "job_df_predict = shuffle(job_df_predict, random_state=0)\n",
    "job_df_predict = job_df_predict[0:10000]\n",
    "\n",
    "X_wo_D = job_df_predict.loc[:, job_df_predict.columns != \"Duration\"]\n",
    "X_wo_AP = job_df_predict.loc[:, job_df_predict.columns != \"AffectedProduction\"]\n",
    "X_wo_GPL = job_df_predict.loc[:, job_df_predict.columns != \"GrossProductionLoss\"]\n",
    "X_wo_DLF = job_df_predict.loc[:, job_df_predict.columns != \"DaysFromLastFailure_int\"]\n",
    "\n",
    "Xs = [X_wo_D, X_wo_AP, X_wo_GPL, X_wo_DLF]\n",
    "y = [\"Duration\",\"AffectedProduction\",\"GrossProductionLoss\",\"DaysFromLastFailure_int\"]\n",
    "\n",
    "for i in range(len(Xs)):\n",
    "    # Normalization\n",
    "    curr_norm_scaler = MinMaxScaler().fit(Xs[i])\n",
    "    Xs[i] = curr_norm_scaler.transform(Xs[i])\n",
    "\n",
    "    # Scaling\n",
    "    curr_std_scaler = MinMaxScaler().fit(Xs[i])\n",
    "    Xs[i] = curr_std_scaler.transform(Xs[i])\n",
    "\n",
    "\n",
    "X_D_train, X_D_test, y_D_train, y_D_test = train_test_split(Xs[0], job_df_predict['Duration'], test_size=0.2, random_state=42)\n",
    "X_AP_train, X_AP_test, y_AP_train, y_AP_test = train_test_split(Xs[1], job_df_predict['AffectedProduction'], test_size=0.2, random_state=42)\n",
    "X_GPL_train, X_GPL_test, y_GPL_train, y_GPL_test = train_test_split(Xs[2], job_df_predict['GrossProductionLoss'], test_size=0.2, random_state=42)\n",
    "X_DLF_train, X_DLF_test, y_DLF_train, y_DLF_test = train_test_split(Xs[3], job_df_predict['DaysFromLastFailure_int'], test_size=0.2, random_state=42)\n",
    "\n",
    "splits = [[X_D_train, X_D_test, y_D_train, y_D_test], [X_AP_train, X_AP_test, y_AP_train, y_AP_test], [X_GPL_train, X_GPL_test, y_GPL_train, y_GPL_test], [X_DLF_train, X_DLF_test, y_DLF_train, y_DLF_test]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff1c043-ca03-4c6c-9564-df9ae199b632",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T18:51:53.050326Z",
     "end_time": "2023-05-02T18:54:15.874024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting:  Duration\n",
      "\n",
      "Training Linear Regression\n",
      "MSE: 189.42219678056188\n",
      "MAE: 4.409601151250547\n",
      "R2: 0.00029889470575283905\n",
      "\n",
      "Training Logistic Regression\n",
      "MSE: 196.97\n",
      "MAE: 2.737\n",
      "R2: -0.03953565134671955\n",
      "\n",
      "Training Decision Tree Regressor\n",
      "MSE: 135.892\n",
      "MAE: 2.962\n",
      "R2: 0.2828117036461978\n",
      "\n",
      "Training Random Forest Regressor\n",
      "MSE: 106.05943994999998\n",
      "MAE: 2.844455\n",
      "R2: 0.4402570493481671\n",
      "\n",
      "Training Random Forest Regressor 2\n",
      "MSE: 110.98586680799998\n",
      "MAE: 2.863916\n",
      "R2: 0.41425716940379487\n",
      "\n",
      "Training Support Vector Regressor\n",
      "MSE: 195.73241546852296\n",
      "MAE: 2.770161181589232\n",
      "R2: -0.033004132628002836\n",
      "\n",
      "Training Support Vector Regressor 2\n",
      "MSE: 195.55568138691004\n",
      "MAE: 2.776513625506563\n",
      "R2: -0.03207139475601917\n",
      "\n",
      "Training Support Vector Regressor 3\n",
      "MSE: 195.91525621970575\n",
      "MAE: 2.8471784868360257\n",
      "R2: -0.03396909926948899\n",
      "\n",
      "Training Support Vector Regressor 4\n",
      "MSE: 195.1220599256563\n",
      "MAE: 2.777691409106238\n",
      "R2: -0.02978289920764965\n",
      "\n",
      "Training K-Nearest Neighbors Regressor\n",
      "MSE: 164.17816\n",
      "MAE: 3.2456000000000005\n",
      "R2: 0.1335276920723667\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting:  AffectedProduction\n",
      "\n",
      "Training Linear Regression\n",
      "MSE: 1555.4038958989775\n",
      "MAE: 6.111190856098741\n",
      "R2: 0.09732596981498798\n",
      "\n",
      "Training Logistic Regression\n",
      "MSE: 1692.4675\n",
      "MAE: 4.2865\n",
      "R2: 0.017781514364049178\n",
      "\n",
      "Training Decision Tree Regressor\n",
      "MSE: 3066.124\n",
      "MAE: 6.633\n",
      "R2: -0.7794159545468637\n",
      "\n",
      "Training Random Forest Regressor\n",
      "MSE: 1677.09968585\n",
      "MAE: 5.089615\n",
      "R2: 0.026700179651239386\n",
      "\n",
      "Training Random Forest Regressor 2\n",
      "MSE: 1676.8079743879998\n",
      "MAE: 5.145536\n",
      "R2: 0.026869473531593635\n",
      "\n",
      "Training Support Vector Regressor\n",
      "MSE: 1667.30130660712\n",
      "MAE: 4.103675836875183\n",
      "R2: 0.032386639935781614\n",
      "\n",
      "Training Support Vector Regressor 2\n",
      "MSE: 1640.1767067450512\n",
      "MAE: 4.04837224826398\n",
      "R2: 0.048128320883866094\n",
      "\n",
      "Training Support Vector Regressor 3\n",
      "MSE: 1670.9753278915064\n",
      "MAE: 4.24215909189002\n",
      "R2: 0.030254432598184833\n",
      "\n",
      "Training Support Vector Regressor 4\n",
      "MSE: 1623.6805525431907\n",
      "MAE: 4.022752779390672\n",
      "R2: 0.05770181496807658\n",
      "\n",
      "Training K-Nearest Neighbors Regressor\n",
      "MSE: 1775.7131599999998\n",
      "MAE: 5.2902000000000005\n",
      "R2: -0.030529857110419334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting:  GrossProductionLoss\n",
      "\n",
      "Training Linear Regression\n",
      "MSE: 467.49259142628733\n",
      "MAE: 5.238113720364121\n",
      "R2: 0.05427499565907923\n",
      "\n",
      "Training Logistic Regression\n",
      "MSE: 501.704\n",
      "MAE: 2.717\n",
      "R2: -0.014933768533679004\n",
      "\n",
      "Training Decision Tree Regressor\n",
      "MSE: 979.359\n",
      "MAE: 5.276\n",
      "R2: -0.9812170535163671\n",
      "\n",
      "Training Random Forest Regressor\n",
      "MSE: 444.15113795\n",
      "MAE: 4.871854999999999\n",
      "R2: 0.10149413152353681\n",
      "\n",
      "Training Random Forest Regressor 2\n",
      "MSE: 434.16329779999995\n",
      "MAE: 4.906472\n",
      "R2: 0.1216992649148424\n",
      "\n",
      "Training Support Vector Regressor\n",
      "MSE: 501.1689932243441\n",
      "MAE: 2.806654940761823\n",
      "R2: -0.013851464141034331\n",
      "\n",
      "Training Support Vector Regressor 2\n",
      "MSE: 501.2387464249533\n",
      "MAE: 2.805728684684992\n",
      "R2: -0.013992572999567576\n",
      "\n",
      "Training Support Vector Regressor 3\n",
      "MSE: 500.6573248829088\n",
      "MAE: 2.900302627028176\n",
      "R2: -0.01281637277638037\n",
      "\n",
      "Training Support Vector Regressor 4\n",
      "MSE: 502.3464116975579\n",
      "MAE: 2.808002557393642\n",
      "R2: -0.01623335020963257\n",
      "\n",
      "Training K-Nearest Neighbors Regressor\n",
      "MSE: 559.98324\n",
      "MAE: 4.783799999999999\n",
      "R2: -0.1328311117489589\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting:  DaysFromLastFailure_int\n",
      "\n",
      "Training Linear Regression\n",
      "MSE: 400786.62604549737\n",
      "MAE: 431.60915092092813\n",
      "R2: 0.04094541632086668\n",
      "\n",
      "Training Logistic Regression\n",
      "MSE: 562640.764\n",
      "MAE: 381.006\n",
      "R2: -0.34636030399296214\n",
      "\n",
      "Training Decision Tree Regressor\n",
      "MSE: 623198.243625\n",
      "MAE: 424.80725\n",
      "R2: -0.4912701503704682\n",
      "\n",
      "Training Random Forest Regressor\n",
      "MSE: 290954.43579547334\n",
      "MAE: 324.2319498333334\n",
      "R2: 0.30376622582274493\n",
      "\n",
      "Training Random Forest Regressor 2\n",
      "MSE: 287436.64820678544\n",
      "MAE: 323.61320584285716\n",
      "R2: 0.3121840474068357\n",
      "\n",
      "Training Support Vector Regressor\n",
      "MSE: 472865.5739474217\n",
      "MAE: 338.95159335207927\n",
      "R2: -0.13153450411505774\n",
      "\n",
      "Training Support Vector Regressor 2\n",
      "MSE: 457521.404581612\n",
      "MAE: 336.30322176571366\n",
      "R2: -0.09481697162594172\n",
      "\n",
      "Training Support Vector Regressor 3\n",
      "MSE: 473022.9585721726\n",
      "MAE: 341.04813388634784\n",
      "R2: -0.1319111146004357\n",
      "\n",
      "Training Support Vector Regressor 4\n",
      "MSE: 445744.1465892\n",
      "MAE: 333.7820810727717\n",
      "R2: -0.06663481052879927\n",
      "\n",
      "Training K-Nearest Neighbors Regressor\n",
      "MSE: 379977.89738\n",
      "MAE: 385.0533\n",
      "R2: 0.09073926000295385\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Random Forest Regressor 2\": RandomForestRegressor(n_estimators=500, random_state=42), \n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Support Vector Regressor 2\": SVR(kernel= 'rbf', C=100, gamma=0.1, epsilon=0.1),\n",
    "    \"Support Vector Regressor 3\": SVR(kernel='linear', C=1, epsilon=0.2, max_iter=10000),\n",
    "    \"Support Vector Regressor 4\": SVR(kernel='poly', degree=3, C=10, epsilon=0.1),\n",
    "    \"K-Nearest Neighbors Regressor\": KNeighborsRegressor(),\n",
    "}\n",
    "i = 0\n",
    "for split in splits:\n",
    "    print(\"Predicting: \", y[i])\n",
    "    print(\"\")\n",
    "    for name, model in models.items():\n",
    "        print(\"Training\", name)\n",
    "\n",
    "        model.fit(split[0], split[2])\n",
    "\n",
    "        y_pred = model.predict(split[1])\n",
    "\n",
    "        mse = mean_squared_error(split[3], y_pred)\n",
    "        mae = mean_absolute_error(split[3], y_pred)\n",
    "        r2 = r2_score(split[3], y_pred)\n",
    "        print(\"MSE:\", mse)\n",
    "        # MAE = 0.5 -> This means that on average, the predicted target values are off by 0.5 units from the true target values.\n",
    "        print(\"MAE:\", mae)\n",
    "        print(\"R2:\", r2)\n",
    "        print(\"\")\n",
    "    i+=1\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting:  Duration\n",
      "\n",
      "Best hyperparameters:  {'max_depth': 50, 'n_estimators': 1000}\n",
      "MSE: 109.73216514600001\n",
      "MAE: 2.8553689999999996\n",
      "R2: 0.42087374844528136\n",
      "\n",
      "Predicting:  AffectedProduction\n",
      "\n",
      "Best hyperparameters:  {'max_depth': 200, 'n_estimators': 1000}\n",
      "MSE: 1653.209754216\n",
      "MAE: 5.117716000000001\n",
      "R2: 0.04056463050272929\n",
      "\n",
      "Predicting:  GrossProductionLoss\n",
      "\n",
      "Best hyperparameters:  {'max_depth': 200, 'n_estimators': 1000}\n",
      "MSE: 434.53569156199995\n",
      "MAE: 4.86575\n",
      "R2: 0.1209459222979904\n",
      "\n",
      "Predicting:  DaysFromLastFailure_int\n",
      "\n",
      "Best hyperparameters:  {'max_depth': 50, 'n_estimators': 1000}\n",
      "MSE: 287957.54010536586\n",
      "MAE: 324.4777097440476\n",
      "R2: 0.31093758924064374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_param_grid = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    # 'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_depth': [50, 200],\n",
    "    # 'min_samples_split': [ 5, 10],\n",
    "    # 'min_samples_leaf': [2, 4],\n",
    "    # 'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "forest_model = RandomForestRegressor()\n",
    "\n",
    "i = 0\n",
    "for split in splits:\n",
    "    print(\"Predicting: \", y[i])\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    grid_search = GridSearchCV(forest_model, forest_param_grid, cv=5)\n",
    "\n",
    "\n",
    "    grid_search.fit(split[0], split[2])\n",
    "\n",
    "\n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(split[1])\n",
    "    mse = mean_squared_error(split[3], y_pred)\n",
    "    mae = mean_absolute_error(split[3], y_pred)\n",
    "    r2 = r2_score(split[3], y_pred)\n",
    "    # MAE = 0.5 -> This means that on average, the predicted target values are off by 0.5 units from the true target values.\n",
    "\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"R2:\", r2)\n",
    "    print(\"\")\n",
    "    i+=1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T19:14:51.461699Z",
     "end_time": "2023-05-02T19:38:33.609920Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e8b11-26c1-4685-afa9-0190d596e8da",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T17:30:09.020238Z",
     "end_time": "2023-05-02T17:39:51.619829Z"
    }
   },
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(50, 25), (100, 50), (100,)],\n",
    "#     'activation': ['relu', 'logistic', 'tanh'],\n",
    "#     'solver': ['adam', 'sgd'],\n",
    "#     'alpha': [0.0001, 0.001, 0.01],\n",
    "#     'batch_size': [32, 64, 128],\n",
    "#     'learning_rate': ['constant', 'adaptive'],\n",
    "#     'max_iter': [2500, 5000],\n",
    "#     'early_stopping': [True, False]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100, 50)],\n",
    "    'activation': ['relu', 'logistic', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [128],\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'max_iter': [5000, 10000],\n",
    "    'early_stopping': [True]\n",
    "}\n",
    "\n",
    "\n",
    "model = MLPRegressor()\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "# MAE = 0.5 -> This means that on average, the predicted target values are off by 0.5 units from the true target values.\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
